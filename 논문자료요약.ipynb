{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import dataset_dict, load_dataset,Dataset,DatasetDict\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반상식문장생성데이터 -> 단어 단위로 분류해서 집합  \n",
    "논문자료요약 -> 기존에서 절반은 요약(0번) 가져오기 -> 나머지 절반은 단어 단위로 분류해서 집합으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_parquet('./13/논문자료요약.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = new_df#[new_df['domain'].isin(domains)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(filtered_df)):\n",
    "    \n",
    "    filtered_df['text'][i] = filtered_df['text'][i].strip()\n",
    "    \n",
    "    try:\n",
    "        if filtered_df['text'][i].endswith('. '):\n",
    "            filtered_df['text'][i]=filtered_df['text'][i][:-1]\n",
    "\n",
    "        elif filtered_df['text'][i].endswith('.'):\n",
    "            pass\n",
    "\n",
    "        elif filtered_df['text'][i].endswith(' .'):\n",
    "            print(i, '번째 문장')\n",
    "            print(filtered_df['text'][i])\n",
    "            filtered_df['text'][i]=filtered_df['text'][i][:-2]+'.'\n",
    "\n",
    "            print(filtered_df['text'][i])\n",
    "            \n",
    "\n",
    "        else:\n",
    "            print(i, '번째 문장')\n",
    "            print(filtered_df['text'][i])\n",
    "\n",
    "\n",
    "            if filtered_df['text'][i].endswith(' '):\n",
    "                filtered_df['text'][i]=filtered_df['text'][i][:-1]+'.'\n",
    "                \n",
    "\n",
    "            else:\n",
    "                filtered_df['text'][i]=filtered_df['text'][i]+'.'\n",
    "                \n",
    "            \n",
    "            print(filtered_df['text'][i])\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(i)\n",
    "        print(filtered_df['text'][i])\n",
    "\n",
    "        print('######################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_index = []\n",
    "for i in range(len(filtered_df)):\n",
    "    text = filtered_df['text'][i]\n",
    "    \n",
    "    if '�' in text:\n",
    "        remove_index.append(i)\n",
    "    elif '삭제.' in text[-5:]:\n",
    "        remove_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df['text'][remove_index[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.drop(remove_index, inplace=True)\n",
    "filtered_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df= filtered_df.dropna(subset=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df=filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_element(text):\n",
    "    return len(text.split('. '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['len_elements'] = filtered_df['text'].apply(lambda x: len(x.split('. ')) if isinstance(x, str) else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_1 = filtered_df[(filtered_df['len_elements'] > 2)&(filtered_df['len_elements'] < 15)] # 15기준\n",
    "filtered_df_2 = filtered_df[filtered_df['len_elements'] <= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_1=filtered_df_1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_2=filtered_df_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_allign_data(text):\n",
    "\n",
    "    if not (text.endswith('.') or text.endswith('. ')):\n",
    "        #print(text)\n",
    "\n",
    "        text+='.'\n",
    "\n",
    "\n",
    "\n",
    "    if text.endswith('.'):\n",
    "        text+=' '\n",
    "\n",
    "\n",
    "\n",
    "    my_list = text.split('. ')\n",
    "    my_list_with_dots = [element + '.' for element in my_list]\n",
    "\n",
    "    if my_list_with_dots[-1]=='.':\n",
    "\n",
    "        my_list_with_dots=my_list_with_dots[:-1]\n",
    "\n",
    "\n",
    "\n",
    "    random.shuffle(my_list_with_dots)\n",
    "\n",
    "\n",
    "    if len(my_list_with_dots)==1:\n",
    "        raise Exception(\"allign 리스트의 길이가 1입니다.\",text)\n",
    "\n",
    "\n",
    "    tmp_input='당신은 인공지능 비서입니다. 주어진 문장 리스트를 모두 활용하여 가장 정확한 단락을 생성하세요.'\n",
    "    tmp_inst=f'이 문장들은 임의의 순서로 섞여 있습니다. 모든 문장을 활용하여 원본 단락의 순서와 내용을 올바른 순서로 재구성하세요.\\n#문장 리스트: {my_list_with_dots}'\n",
    "    \n",
    "    \n",
    "    if text.endswith(' '):\n",
    "        tmp_out=text[:-1]\n",
    "\n",
    "    else:\n",
    "        tmp_out=text\n",
    "\n",
    "        \n",
    "\n",
    "    return tmp_input, tmp_inst, tmp_out\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_completion_data(text):\n",
    "\n",
    "\n",
    "    if not (text.endswith('.') or text.endswith('. ')):\n",
    "        #print(text)\n",
    "\n",
    "        text+='.'\n",
    "\n",
    "\n",
    "\n",
    "    if text.endswith('. '):\n",
    "        text=text\n",
    "\n",
    "    else:\n",
    "        text=text+' '\n",
    "\n",
    "\n",
    "\n",
    "    my_list_with_dots = text.split('. ')\n",
    "\n",
    "\n",
    "#    print(my_list_with_dots)\n",
    "\n",
    "\n",
    "    # ㅁㅁㅁㅁㅁ. 이렇게 공백있이 끝난경우\n",
    "    if my_list_with_dots[-1]=='':\n",
    "\n",
    "        my_list_with_dots=my_list_with_dots[:-1]\n",
    "\n",
    "        if len(my_list_with_dots)==1:\n",
    "            raise Exception(\"Completion 텍스트를 나눈  리스트의 길이가 1입니다.\",text)\n",
    "\n",
    "        last_sentence=my_list_with_dots.pop()\n",
    "        last_sentence+='.'\n",
    "\n",
    "\n",
    "        \n",
    "    remaining_paragraph=''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(my_list_with_dots)):\n",
    "        \n",
    "        if i!=len(my_list_with_dots)-1:\n",
    "            remaining_paragraph+=my_list_with_dots[i]+'. '\n",
    "\n",
    "        else:\n",
    "            remaining_paragraph+=my_list_with_dots[i]+'.'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    tmp_input='당신은 인공지능 비서입니다. 주어진 원문을 바탕으로 주어진 질문에 가장 적절한 답변을 생성하세요.'\n",
    "\n",
    "    tmp_instruct=f'다음 텍스트에서 제공된 문맥을 정확히 이해하고, 마지막 문장을 자연스럽고 문맥에 맞게 완성하세요. 문장은 이전 내용과 논리적으로 연결되어야 합니다.\\n#텍스트: {remaining_paragraph}'\n",
    "\n",
    "    tmp_output=last_sentence\n",
    "\n",
    "\n",
    "    return tmp_input, tmp_instruct, tmp_output\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_text_mask_data(text):\n",
    "\n",
    "\n",
    "    if not (text.endswith('.') or text.endswith('. ')):\n",
    "        #print(text)\n",
    "\n",
    "        text+='.'\n",
    "\n",
    "    if text.endswith('. '):\n",
    "        text=text[:-1]\n",
    "\n",
    "    else:\n",
    "        text=text\n",
    "\n",
    "\n",
    "    words = re.findall(r'[가-힣]{2,}', text)\n",
    "    \n",
    "    random_word = random.choice(words)\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "    masked_text = text.replace(random_word, \"<MASK>\")\n",
    "\n",
    "\n",
    "    tmp_input='당신은 인공지능 비서입니다. 주어진 질문에 가장 적절한 답변을 제공하세요.'\n",
    "    tmp_instruct=f'이 문제에서는 주어진 텍스트 내의 <MASK>로 표시된 부분에 들어갈 적절한 단어를 예측해야 합니다. <MASK>가 위치한 문장의 전체 문맥을 분석하여, 문장의 나머지 내용과 일관되게 <MASK>에 들어갈 가장 적합한 단어를 답하세요.\\n#텍스트: {masked_text}'\n",
    "    tmp_output=random_word\n",
    "\n",
    "\n",
    "\n",
    "    return tmp_input, tmp_instruct, tmp_output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_align(text):\n",
    "\n",
    "    word_lst=[]\n",
    "    for word in text.split(' '):\n",
    "        out = re.sub(r\"[^\\w\\s]\", \"\", word)\n",
    "        word_lst.append(out)\n",
    "\n",
    "\n",
    "    # 중복 제거하기 위해 set으로 만듬\n",
    "    word_lst=set(word_lst)\n",
    "\n",
    "\n",
    "    # 다시 리스트 형식으로 돌림\n",
    "    word_lst=list(word_lst)\n",
    "\n",
    "\n",
    "    # 랜덤하게 재배열\n",
    "    random.shuffle(word_lst)\n",
    "\n",
    "\n",
    "    tmp_input= '당신은 인공지능 비서입니다. 주어진 지시사항에 따라 가장 적절한 문장을 생성하세요.'\n",
    "    tmp_instruct=f'이 문제에는 문장에서 공백을 기준으로 나누고, 구두점을 제거한 무작위로 섞인 단어들이 담긴 리스트가 제공됩니다. 이 리스트의 단어를 모두 활용하여 가장 문맥상 적절한 문장을 생성하세요.\\n#단어리스트: {word_lst}'\n",
    "    tmp_output=text\n",
    "\n",
    "    return tmp_input, tmp_instruct, tmp_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[]\n",
    "output_lst=[]\n",
    "inst_lst=[]\n",
    "id_lst=[]\n",
    "\n",
    "\n",
    "for i in range(len(filtered_df_1)):\n",
    "    try:\n",
    "\n",
    "        text=filtered_df_1['text'][i]\n",
    "\n",
    "        \n",
    "\n",
    "        thred=random.random()\n",
    "\n",
    "\n",
    "\n",
    "        if thred < 0.44 :\n",
    "\n",
    "            tmp_input, tmp_instruct, tmp_output = make_completion_data(text)\n",
    "            tmp_id='completion_aihub'\n",
    "\n",
    "        elif thred < 0.88:\n",
    "            tmp_input, tmp_instruct, tmp_output = make_text_allign_data(text)\n",
    "            tmp_id='text_allign_aihub'\n",
    "      \n",
    "\n",
    "\n",
    "        else:\n",
    "            \n",
    "            tmp_input, tmp_instruct, tmp_output = make_text_mask_data(text)\n",
    "            tmp_id='pre_mask_aihub'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        input_lst.append(tmp_input)\n",
    "        inst_lst.append(tmp_instruct)\n",
    "        output_lst.append(tmp_output)\n",
    "        id_lst.append(tmp_id)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(e)\n",
    "        print(filtered_df_1['text'][i])\n",
    "        print('what_the Fuck?')\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inst_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_df_1=pd.DataFrame({'input':input_lst,'instruction':inst_lst,'output':output_lst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lst=[]\n",
    "output_lst=[]\n",
    "inst_lst=[]\n",
    "id_lst=[]\n",
    "\n",
    "\n",
    "for i in range(len(filtered_df_2)):\n",
    "    try:\n",
    "\n",
    "        text=filtered_df_2['text'][i]\n",
    "\n",
    "        \n",
    "\n",
    "        thred=random.random()\n",
    "\n",
    "        if thred < 0.56 :\n",
    "\n",
    "            tmp_input, tmp_instruct, tmp_output = make_word_align(text)\n",
    "            tmp_id='word_allign_aihub'\n",
    "\n",
    "        else:\n",
    "            \n",
    "            tmp_input, tmp_instruct, tmp_output = make_text_mask_data(text)\n",
    "            tmp_id='pre_mask_aihub'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        input_lst.append(tmp_input)\n",
    "        inst_lst.append(tmp_instruct)\n",
    "        output_lst.append(tmp_output)\n",
    "        id_lst.append(tmp_id)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(e)\n",
    "        print(filtered_df_2['text'][i])\n",
    "        print('what_the Fuck?')\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(output_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_df_2=pd.DataFrame({'input':input_lst,'instruction':inst_lst,'output':output_lst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hub_df=pd.concat([hub_df_1,hub_df_2],axis=0)\n",
    "hub_df = hub_df_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_df=hub_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_df.iloc[0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df=pd.concat([concat_df,hub_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_df.to_parquet('./Save/논문자료요약.parquet', engine = 'pyarrow', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimv",
   "language": "python",
   "name": "aimv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
